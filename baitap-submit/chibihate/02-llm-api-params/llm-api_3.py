import os
from openai import OpenAI
from dotenv import load_dotenv
import requests
from bs4 import BeautifulSoup

# Load environment variables from .env file
load_dotenv()

client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ_API_KEY"),
)

def get_text_from_html(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.find(id='main-detail')  
        
        if content_div:
            return content_div.get_text(separator='\n', strip=True)
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung ch√≠nh.")
            return None
    except Exception as e:
        print(f"‚ùå Error parsing HTML: {e}")
        return None

def summarize_content(content, url):
    prompt = f"""T√≥m t·∫Øt ng·∫Øn g·ªçn v√† d·ªÖ hi·ªÉu n·ªôi dung c·ªßa b√†i b√°o d∆∞·ªõi ƒë√¢y. Gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng, r√µ r√†ng.
        URL: {url}
        N·ªôi dung:
        \"\"\"
        {content}
        \"\"\"
        """
    messages = [
        {"role": "system", "content": "B·∫°n l√† m·ªôt tr·ª£ l√Ω t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát.",}
    ]
    messages.append({
                "role": "user",
                "content": prompt
    })
    stream = client.chat.completions.create(
        messages = messages,
        model="gemma2-9b-it",
        stream=True
    )
    for chunk in stream:
        content = chunk.choices[0].delta.content
        if content != None:
            print(content, end="", flush=True)

print("üîó D√°n link b√†i b√°o (ho·∫∑c nh·∫≠p 'exit' ƒë·ªÉ tho√°t):")
while True:
    url = input("URL: ").strip()
    if url.lower() in ['exit', 'quit']:
        print("üëã T·∫°m bi·ªát!")
        break

    content = get_text_from_html(url)    
    if not content:
        print("‚ö†Ô∏è Kh√¥ng l·∫•y ƒë∆∞·ª£c n·ªôi dung t·ª´ trang web.")
        continue
    
    print("‚è≥ ƒêang t√≥m t·∫Øt n·ªôi dung...\n")
    summary = summarize_content(content, url)